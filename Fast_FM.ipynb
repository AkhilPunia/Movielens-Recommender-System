{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error;\n",
    "from sklearn.model_selection import train_test_split,ShuffleSplit,GridSearchCV;\n",
    "from fastFM.mcmc import FMClassification, FMRegression;\n",
    "from sklearn.preprocessing import OneHotEncoder;\n",
    "from fastFM import als;\n",
    "from sklearn.feature_extraction.text import CountVectorizer;\n",
    "import gc;\n",
    "import pickle;\n",
    "import random;\n",
    "import matplotlib.pyplot as plt;\n",
    "import time;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doumentation : http://ibayer.github.io/fastFM/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model A: Basic model with just userId and movieId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    \n",
    "    '''\n",
    "    Input : train and test sets\n",
    "    Output : One hot encoded datasets\n",
    "    '''\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore').fit(df)\n",
    "    #trainX = encoder.transform(trainX)\n",
    "    #testX = encoder.transform(testX)\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771354587448218"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = np.genfromtxt('./ml-1m/ratings.dat',delimiter=\"::\")\n",
    "ratings =  pd.DataFrame(ratings)\n",
    "\n",
    "ratings.columns = ['userId','movieId','rating','timestamp']\n",
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "y = ratings['rating'].values\n",
    "X = ratings.drop('rating', axis=1)\n",
    "\n",
    "#trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.20, random_state=1234)\n",
    "#trainX, testX = encode(trainX,testX)\n",
    "\n",
    "encoder = encode(X)\n",
    "\n",
    "##fixed\n",
    "#trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.10, random_state=1234)\n",
    "trainX = encoder.transform(trainX)\n",
    "testX = encoder.transform(testX)\n",
    "\n",
    "cv = ShuffleSplit(n_splits=3, test_size= int(0.2 * trainX.shape[0]), random_state = 2018)\n",
    "\n",
    "\n",
    "estimator = als.FMRegression()\n",
    "\n",
    "params = {\n",
    "'n_iter' : np.arange(10,100,30),\n",
    "'rank' :  np.arange(2,12,4),\n",
    "'l2_reg_w': np.logspace(-6, -1, 3),\n",
    "'l2_reg_V' : np.logspace(-6, -1, 3)\n",
    "}\n",
    "\n",
    "###Gridsearch over parameters\n",
    "regressor = GridSearchCV(estimator=estimator , cv=cv, param_grid=params)\n",
    "regressor.fit(trainX, trainY)\n",
    "\n",
    "###get RMSE\n",
    "mean_squared_error(regressor.predict(testX),testY)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B : Adding user data, genre, year of movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/som/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId gender  age  occupation    zip\n",
       "0       1      F    1          10  48067\n",
       "1       2      M   56          16  70072\n",
       "2       3      M   25          15  55117\n",
       "3       4      M   45           7  02460\n",
       "4       5      M   25          20  55455"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('./ml-1m/users.dat', sep='::', names=['userId', 'gender', 'age', 'occupation', 'zip'], \\\n",
    "                    header=None)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8783405327095336"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./ml-1m/movies.dat', sep='::', names=['movieId', 'title', 'genres'], header=None)\n",
    "movies.head()\n",
    "movies['year'] = movies.title.apply(lambda x : x[-5:-1])\n",
    "\n",
    "sparse_genres = pandas.DataFrame(CountVectorizer().fit_transform(movies.genres\\\n",
    "                                .map(lambda x: x.replace('|', ' '))).todense())\n",
    "\n",
    "movies = pandas.concat([movies[['movieId']], sparse_genres], axis=1) \n",
    "\n",
    "\n",
    "ratings = np.genfromtxt('./ml-1m/ratings.dat',delimiter=\"::\")\n",
    "ratings =  pd.DataFrame(ratings)\n",
    "\n",
    "ratings.columns = ['userId','movieId','rating','timestamp']\n",
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "\n",
    "ratings = pandas.merge(pandas.merge(ratings, users, on='userId'), movies, on='movieId')\n",
    "\n",
    "\n",
    "y = ratings['rating'].values\n",
    "X = ratings.drop('rating', axis=1)\n",
    "\n",
    "for feature in X.columns:\n",
    "    _,X[feature] = numpy.unique(X[feature], return_inverse=True)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.20, random_state=1234)\n",
    "encoder = encode(X)\n",
    "\n",
    "##fixed\n",
    "#trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.10, random_state=1234)\n",
    "trainX = encoder.transform(trainX)\n",
    "testX = encoder.transform(testX)\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=3, test_size= int(0.2 * trainX.shape[0]), random_state = 2018)\n",
    "estimator2 = als.FMRegression()\n",
    "\n",
    "params = {\n",
    "'n_iter' : np.arange(10,100,30),\n",
    "'rank' :  np.arange(2,12,4),\n",
    "'l2_reg_w': np.logspace(-6, -1, 3),\n",
    "'l2_reg_V' : np.logspace(-6, -1, 3)\n",
    "}\n",
    "\n",
    "###Gridsearch over parameters\n",
    "regressor2 = GridSearchCV(estimator=estimator2 , cv=cv, param_grid=params)\n",
    "regressor2.fit(trainX, trainY)\n",
    "\n",
    "###get RMSE\n",
    "mean_squared_error(regressor2.predict(testX),testY)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(regressor,open(\"./dump_regressor1\",\"wb\"))\n",
    "pickle.dump(regressor2,open(\"./dump_regressor2\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=2018, test_size=160033, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=FMRegression(init_stdev=0.1, l2_reg=0, l2_reg_V=0.1, l2_reg_w=0.1, n_iter=100,\n",
       "       random_state=123, rank=8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_iter': array([10, 40, 70]), 'rank': array([ 2,  6, 10]), 'l2_reg_w': array([1.00000e-06, 3.16228e-04, 1.00000e-01]), 'l2_reg_V': array([1.00000e-06, 3.16228e-04, 1.00000e-01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor1 = pickle.load(open(\"./dump_regressor\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Factorization Machines have been described as state of the art for many recommendation systems. \n",
    "\n",
    "Yet, experience has shown these models to suffer from slowtraining and local minima. Use a large(ish) dataset and characterize where FMs are easy to fit and accurate and where they are not.\n",
    "\n",
    "1. Start with models that have no side information, and are only user and item ratings.\n",
    "Specifically, subsample datasets from small to large, and subsample users/items\n",
    "from sparsely-populated to well-populated, and train and test FMs. Where do they\n",
    "work the best? Where do they fail? Can you set good rules of thumbs for their\n",
    "training and use?\n",
    "2. Next use side information about users or items. Answer the same questions as\n",
    "above.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor 1 : No side information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_simple(file_):\n",
    "    \n",
    "    '''\n",
    "    Input \n",
    "    \n",
    "        File_ : file name of the ratings file\n",
    "    \n",
    "    Output : test - train dfs\n",
    "    '''\n",
    "\n",
    "    ratings = np.genfromtxt(file_,delimiter=\"::\")\n",
    "    ratings =  pd.DataFrame(ratings)\n",
    "    \n",
    "    ratings.columns = ['userId','movieId','rating','timestamp']\n",
    "    ratings = ratings.drop('timestamp', axis=1)\n",
    "    \n",
    "    y = ratings['rating'].values\n",
    "    X = ratings.drop('rating', axis=1)\n",
    "    \n",
    "    encoder = encode(X)\n",
    "    \n",
    "\n",
    "    \n",
    "    ##fixed\n",
    "    trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.10, random_state=1234)\n",
    "    trainX = encoder.transform(trainX)\n",
    "    testX = encoder.transform(testX)\n",
    "    \n",
    "    return (X.userId.nunique(),X.movieId.nunique()),trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsample data from small to large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can grid search do this directly?\n",
    "\n",
    "#train vs test error as data increase? vs a benchmark model, with and without early stopping vs SVD\n",
    "#time taken to run the model\n",
    "#Will try all k, epoch hyperspace together \n",
    "\n",
    "##FM without early stopping ?\n",
    "\n",
    "\n",
    "\n",
    "# For the best iteration - check for local optima\n",
    "\n",
    "#local optima - by sgd vs gd and changing random state?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_user_item(fname,sample_by_=\"All\"):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Input : trainX, testX, trainY, testY : dfs from the load_Data_Simple function\n",
    "    \n",
    "    sample_by_ : \n",
    "        All   -   small to large\n",
    "        Items -   less to many\n",
    "        Users -   less to many \n",
    "    \n",
    "    '''\n",
    "    cnt,trainX, testX, trainY, testY = load_data_simple(fname)  \n",
    "    \n",
    "    if sample_by_ == \"All\":\n",
    "        #cv = ShuffleSplit(n_splits=10, test_size= int(0.2 * trainX.shape[0]), random_state = 2018)\n",
    "        \n",
    "        model_run = {}\n",
    "        #keep lambda at\n",
    "        _l = trainX.shape[0]\n",
    "        \n",
    "        ###10% for cv\n",
    "        setcv = set(random.sample(range(_l), int(_l * .10)))\n",
    "        potentialtrain = set(range(_l)) - setcv\n",
    "        \n",
    "        for i in np.arange(.2,1.01,0.2):\n",
    "            #local split \n",
    "            settrain = random.sample(potentialtrain, int(len(potentialtrain) * i))\n",
    "            print(\"model_\" + sample_by_ +\"_\"+ str(i))\n",
    "            model_run[\"model_\" + sample_by_ +\"_\"+ str(i)] = fm_model(setcv,settrain,trainX,testX,trainY,testY)\n",
    "        \n",
    "        #return statistics\n",
    "        return model_run\n",
    "\n",
    "    if sample_by_ == \"Items\":\n",
    "        # number of items in the dataset : \n",
    "        nusers = cnt[0]\n",
    "        nitems = cnt[1]\n",
    "        ###**modify**\n",
    "        \n",
    "        model_run = {}\n",
    "        #keep lambda at\n",
    "        _l = trainX.shape[0]\n",
    "        \n",
    "        ###10% for cv\n",
    "        setcv = set(random.sample(range(_l), int(_l * .10)))\n",
    "        potentialtrain = set(range(_l)) - setcv\n",
    "        \n",
    "        \n",
    "        for i in [1,5,25,125,625,np.inf]:    #i defines atmost # of movies/items to be sampled\n",
    "            #local split \n",
    "            settrain = set()\n",
    "            #adds additional 1 min per model\n",
    "            for j in range(nusers,nusers+nitems): #loop through movie columns\n",
    "            #list(potentialtrain)# too much time to slice\n",
    "                train_indices = np.argwhere(trainX[:,j])[:,0] #get non-zero indices which are legal \n",
    "                \n",
    "                cand_indices = potentialtrain.intersection(set(train_indices))\n",
    "                settrain.update(random.sample(cand_indices, min(i,len(cand_indices))))\n",
    "                \n",
    "\n",
    "            print(\"CV size\",len(setcv)/(len(settrain)+len(setcv)))\n",
    "            \n",
    "            print(\"model_\" + sample_by_ +\"_\"+ str(i))\n",
    "            model_run[\"model_\" + sample_by_ +\"_\"+ str(i)] = fm_model(setcv,settrain,trainX,testX,trainY,testY)        \n",
    "        \n",
    "        \n",
    "        return model_run\n",
    "    \n",
    "    \n",
    "    if sample_by_ == \"Users\":\n",
    "        # number of items in the dataset : \n",
    "        nusers = cnt[0]\n",
    "        #nitems = cnt[1]\n",
    "        ###**modify**\n",
    "        \n",
    "        model_run = {}\n",
    "        #keep lambda at\n",
    "        _l = trainX.shape[0]\n",
    "        \n",
    "        ###10% for cv\n",
    "        setcv = set(random.sample(range(_l), int(_l * .10)))\n",
    "        potentialtrain = set(range(_l)) - setcv\n",
    "        \n",
    "        \n",
    "        for i in [1,2,4,16,32,np.inf]:    #i defines atmost # of movies/items to be sampled\n",
    "            #local split \n",
    "            settrain = set()\n",
    "            #adds additional 1 min per model\n",
    "            for j in range(nusers): #loop through movie columns\n",
    "            #list(potentialtrain)# too much time to slice\n",
    "                train_indices = np.argwhere(trainX[:,j])[:,0] #get non-zero indices which are legal \n",
    "                \n",
    "                cand_indices = potentialtrain.intersection(set(train_indices))\n",
    "                settrain.update(random.sample(cand_indices, min(i,len(cand_indices))))\n",
    "                \n",
    "\n",
    "            print(\"CV size\",len(setcv)/(len(settrain)+len(setcv)))\n",
    "            \n",
    "            print(\"model_\" + sample_by_ +\"_\"+ str(i))\n",
    "            model_run[\"model_\" + sample_by_ +\"_\"+ str(i)] = fm_model(setcv,settrain,trainX,testX,trainY,testY)        \n",
    "        \n",
    "        \n",
    "        return model_run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_model(setcv,settrain,trainX,testX,trainY,testY):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    return:\n",
    "        dict of dict  to store size, time for run, train error, test error etc.\n",
    "    '''\n",
    "    \n",
    "    ##Optimise with cv\n",
    "\n",
    "    model_summary = {}\n",
    "    _ = \"_\"\n",
    "    \n",
    "    \n",
    "    ##Get baseline once\n",
    "    #https://surprise.readthedocs.io/en/stable/\n",
    "                #basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly\n",
    "    \n",
    "    \n",
    "    \n",
    "    itercnt = 0\n",
    "    ##24 models : hyperspace\n",
    "    for n_iter in np.arange(50,100,25):\n",
    "        for rank in  np.arange(2,8,2):\n",
    "            for l2_reg in np.logspace(-4, 0, 4): \n",
    "                ##future plan : further granular level regularization\n",
    "                    \n",
    "                start = time.time()\n",
    "                \n",
    "                #als : coordinate descent\n",
    "                estimator_x = als.FMRegression(n_iter = int(n_iter), rank = int(rank), l2_reg = l2_reg)\n",
    "                estimator_x.fit(trainX[list(settrain)],trainY[list(settrain)])\n",
    "                \n",
    "                #estimator_x.fit(trainX[list(settrain)],trainY[list(settrain)])\n",
    "                \n",
    "                \n",
    "                \n",
    "                ###get RMSE\n",
    "                train_rmse = mean_squared_error(estimator_x.predict(trainX[list(settrain)]),trainY[list(settrain)])**0.5\n",
    "                cv_rmse =    mean_squared_error(estimator_x.predict(trainX[list(setcv)]),trainY[list(setcv)])**0.5\n",
    "                \n",
    "                #not being used for evaluation *********\n",
    "                test_rmse = mean_squared_error(estimator_x.predict(testX),testY)**0.5\n",
    "                \n",
    "                #average rating of the train set\n",
    "                baseline = np.mean(trainY[list(settrain)])\n",
    "                train_baseline = mean_squared_error(np.repeat(baseline,len(testY)),testY)**0.5\n",
    "                \n",
    "                #Model summary to be returned for all model\n",
    "                itercnt += 1\n",
    "                model_ = {\n",
    "                'train_rmse' : train_rmse,\n",
    "                'test_rmse' : test_rmse,\n",
    "                'cv_rmse' : cv_rmse,\n",
    "                'train_baseline_rmse' : train_baseline,\n",
    "                'model_obj' : estimator_x,\n",
    "                'n_iter' : n_iter,\n",
    "                'rank' :  rank, #k\n",
    "                'l2_reg' : l2_reg,\n",
    "                'train_size':len(settrain),\n",
    "                #'l2_reg_V':l2_reg_V, #future\n",
    "                #'l2_reg_w' : l2_reg_w,\n",
    "                    \n",
    "                'time' : time.time() - start\n",
    "                    }\n",
    "                \n",
    "                print(\"\\n Model \" + str(itercnt) + \"done.\" + \"\\t CV RMSE: \" + str(cv_rmse))\n",
    "                model_summary[\"model_seq_ \"+str(itercnt) + _ + str(n_iter) +_+ str(rank) +_+ str(l2_reg)] = model_\n",
    "\n",
    "\n",
    "    \n",
    "    return model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1922"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsample data from small to large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###store function return\n",
    "#trainX, testX, trainY, testY = load_data_simple('./ml-1m/ratings.dat')\n",
    "basic_model = subsample_user_item('./ml-1m/ratings.dat')\n",
    "#pickle object for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(basic_model,open(\"./dump_basic_model\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  model_All_1.0_model_seq_ 12_50_6_1.0 \t best cv error 0.8668426911401514\n"
     ]
    }
   ],
   "source": [
    "#check best RMSE\n",
    "m = {}\n",
    "mi = 10.0\n",
    "\n",
    "for key in basic_model.keys():\n",
    "    for k2 in basic_model[key].keys():\n",
    "        if basic_model[key][k2][\"cv_rmse\"] <= mi:\n",
    "            mi = basic_model[key][k2][\"cv_rmse\"]\n",
    "            m[basic_model[key][k2][\"cv_rmse\"]] = key+\"_\"+k2\n",
    "        \n",
    "        \n",
    "print(\"Best model: \",m[mi],\"\\t\",\"best cv error\",mi)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsample user/items from sparsely populated to well populated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsample user/items\n",
    "#Same performance graphs for low number of items to high, same for users.\n",
    "\n",
    "##- where do they fail? where do they work best?\n",
    "basic_model_sub_items = subsample_user_item('./ml-1m/ratings.dat','Items')\n",
    "#basic_model_sub_users = subsample_user_item('./ml-1m/ratings.dat','Users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(basic_model_sub_items,open(\"./dump_basic_model_sub_items\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  model_Items_inf_model_seq_ 12_50_6_1.0 \t best cv error 0.8603343366912477\n"
     ]
    }
   ],
   "source": [
    "#check best RMSE\n",
    "m = {}\n",
    "mi = 10.0\n",
    "\n",
    "for key in basic_model_sub_items.keys():\n",
    "    for k2 in basic_model_sub_items[key].keys():\n",
    "        if basic_model_sub_items[key][k2][\"cv_rmse\"] <= mi:\n",
    "            mi = basic_model_sub_items[key][k2][\"cv_rmse\"]\n",
    "            m[basic_model_sub_items[key][k2][\"cv_rmse\"]] = key+\"_\"+k2\n",
    "        \n",
    "        \n",
    "print(\"Best model: \",m[mi],\"\\t\",\"best cv error\",mi)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model_sub_users = subsample_user_item('./ml-1m/ratings.dat','Users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(basic_model_sub_users,open(\"./dump_basic_model_sub_users\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  model_Users_inf_model_seq_ 20_75_4_1.0 \t best cv error 0.8651680026818478\n"
     ]
    }
   ],
   "source": [
    "#check best RMSE\n",
    "m = {}\n",
    "mi = 10.0\n",
    "\n",
    "for key in basic_model_sub_users.keys():\n",
    "    for k2 in basic_model_sub_users[key].keys():\n",
    "        if basic_model_sub_users[key][k2][\"cv_rmse\"] <= mi:\n",
    "            mi = basic_model_sub_users[key][k2][\"cv_rmse\"]\n",
    "            m[basic_model_sub_users[key][k2][\"cv_rmse\"]] = key+\"_\"+k2\n",
    "        \n",
    "        \n",
    "print(\"Best model: \",m[mi],\"\\t\",\"best cv error\",mi)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor 2: Side information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add feature 1 : performe the test1 and test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add feature 2 : performe the test1 and test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repeat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
