{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import time;\n",
    "import sagemaker as sg;\n",
    "import scipy;\n",
    "import csv;\n",
    "import xlearn as xl;\n",
    "import random;\n",
    "from tqdm import tqdm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "dataLink :  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "groupLens: https://grouplens.org/datasets/movielens/\n",
    "readMe: http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
    "\n",
    "The data are contained in the files links.csv, movies.csv, ratings.csv and tags.csv. More details about the contents and use of all these files follows.\n",
    "\n",
    "This is a development dataset. As such, it may change over time and is not an appropriate dataset for shared research results. See available benchmark datasets if that is your intent.\n",
    "\n",
    "This and other GroupLens data sets are publicly available for download at http://grouplens.org/datasets/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genome_scores = pd.read_csv('ml-latest/genome-scores.csv')\n",
    "#genome_tags = pd.read_csv('ml-latest/genome-tags.csv')\n",
    "#links = pd.read_csv('ml-latest-small/links.csv')\n",
    "#movies = pd.read_csv('ml-1m/movies.dat')\n",
    "#ratings = pd.read_csv('ml-1m/ratings.dat')\n",
    "#users = pd.read_csv('ml-1m/users.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1::F::1::10::48067\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat_file = open('ml-1m/users.dat','r')\n",
    "rat_file.readline()\n",
    "rat_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3::M::25::15::55117\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing data in libsvm & libffm format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Convert data to libsvm format\n",
    "\n",
    "\n",
    "### reading & convert ratings file\n",
    "\n",
    "def convert_ratings_to_fm(fin,fout,feature_index,rating_index,_model = \"fm\"):\n",
    "    '''\n",
    "    Input : ratings file with columns in the following order\n",
    "            1) user_id\n",
    "            2) movie_id\n",
    "            3) rating\n",
    "            4) timestamp - Ignoring this column for now\n",
    "            \n",
    "    Arguments : fin : input ratings file\n",
    "                fout : output file name - column indices to be included\n",
    "                column index containing the rating\n",
    "                _model : ffm/fm\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "            ratings matrix transformed to libsvm\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    rat_file = open(fin,'r')  #input file\n",
    "    text_file = open(fout,'w') #output file\n",
    "    \n",
    "    \n",
    "    if _model==\"ffm\":\n",
    "        add_field = 1\n",
    "    else:\n",
    "        add_field = 0\n",
    "    \n",
    "    \n",
    "    #Initialize ::\n",
    "    val0 = rat_file.readline();\n",
    "    split_row0 = val0.split('::')\n",
    "    datastring = \"\"  #stores the final string\n",
    "    indx_cntr = 0\n",
    "    d_field = {}\n",
    "\n",
    "    ###User\n",
    "    d_field[feature_index[0]] = {split_row0[0] : indx_cntr}\n",
    "    indx_cntr = indx_cntr + 1\n",
    "    ###movie\n",
    "    d_field[feature_index[1]] = {split_row0[1] : indx_cntr}\n",
    "    indx_cntr = indx_cntr + 1\n",
    "    ###first string\n",
    "    ###rating\n",
    "    datastring += str(int(split_row0[rating_index]))\n",
    "    ###user   \n",
    "    datastring += \",\" + (\"0\" + \":\") * add_field + str(d_field[0][split_row0[0]]) + \":\" + \"1\"\n",
    "    ###movie\n",
    "    datastring += \",\" + (\"1\" + \":\") * add_field + str(d_field[1][split_row0[1]]) + \":\" + \"1\"\n",
    "    \n",
    "    datastring += \"\\n\"\n",
    "    text_file.write(datastring) \n",
    "    \n",
    "    #iterate over all the lines\n",
    "    for val in rat_file.readlines():\n",
    "\n",
    "        #split each row\n",
    "        split_row = val.split('::')\n",
    "        #rating\n",
    "        datastring = str(int(split_row[rating_index]))\n",
    "        for col in feature_index: #ignoring timestamp, rating\n",
    "           \n",
    "            #if a new user/movie found, add it to dictionary\n",
    "            if d_field[col].get(split_row[col],None) == None:\n",
    "                d_field[col][split_row[int(col)]] = indx_cntr\n",
    "                indx_cntr += 1\n",
    "\n",
    "            datastring += \",\" + (str(col) + \":\") * add_field + str(d_field[col][split_row[col]]) + \":\" + \"1\"\n",
    "        datastring += \"\\n\"\n",
    "        text_file.write(datastring)        \n",
    "         \n",
    "    text_file.close()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running a basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_ratings_to_fm(\"Test_new_v1.dat\",\"fout\",[0,1],2,_model = \"fm\")\n",
    "fm_model = xl.create_fm()\n",
    "fm_model.setTrain(\"./fout\")\n",
    "#fm_model.setValidate(\"./small_test.txt\")\n",
    "param = {'task':'reg', 'lr':0.2, 'lambda':0.002}\n",
    "\n",
    "fm_model.fit(param, \"./model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_ratings_to_fm(\"Test_new_v1.dat\",\"fout.2\",[0,1],2,_model = \"ffm\")\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"./testffm.txt\")\n",
    "#fm_model.setValidate(\"./small_test.txt\")\n",
    "param = {'task':'reg', 'lr':0.2, 'lambda':0.002}\n",
    "\n",
    "ffm_model.fit(param, \"./model.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a train - test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Benchmark it with Matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_k(data, k):\n",
    "    indice = get_indices(data)\n",
    "    ratios = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    \n",
    "    scores = dict()\n",
    "    \n",
    "    for ratio in tqdm(ratios):\n",
    "        test = select_test(indice, ratio)\n",
    "        new_data = mutate_ratings(data, test)\n",
    "        pred = matrix_factorization(new_data,0.0002,1000, k = k)\n",
    "        y_true, y_pred = fetch_ratings(data, pred, test)\n",
    "        score = np.sqrt(mse(y_true, y_pred))\n",
    "        scores[str(ratio)] = score\n",
    "        \n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_test(indice, ratio):\n",
    "    random.seed(2018)\n",
    "    test = random.sample(indice, int(ratio*len(indice)))\n",
    "    return(test)\n",
    "\n",
    "test = select_test(indice, 0.1)\n",
    "\n",
    "\n",
    "def mutate_ratings(ratings,test):\n",
    "    rt = ratings.copy()\n",
    "    for i in test:\n",
    "        rt[i[0]][i[1]] = np.nan\n",
    "    return (rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Convert data to libsvm format\n",
    "\n",
    "\n",
    "### reading ratings file\n",
    "def convert_to_fm(filename,df,_type,features,_model = \"fm\",label = \"rating\"):\n",
    "    '''\n",
    "    Input : ratings file with columns in the following order\n",
    "            1) user_id\n",
    "            2) movie_id\n",
    "            3) rating\n",
    "            4) timestamp - Ignoring this column for now\n",
    "    \n",
    "    Output:\n",
    "            ratings matrix transformed to libsvm\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #store fields for ffm\n",
    "    df = df[features]\n",
    "    \n",
    "    \n",
    "    #get total number of indices required\n",
    "    field_list = list(df.columns)\n",
    "    field_list.remove(label)\n",
    "    \n",
    "    #index count\n",
    "    ind_cnt = -1\n",
    "    \n",
    "    #ind_dict is a dictionary of dictionary\n",
    "    ind_dict = {}\n",
    "    \n",
    "    for col in  field_list:\n",
    "        sub_dict = {}\n",
    "        #maintains unique indices for unique values in each of the field\n",
    "        sub_dict = dict(zip(df[col].unique(),map(lambda x : x + ind_cnt + 1,range(df[col].nunique()))))\n",
    "        #sub_dict should have global indices against each unique value in the field\n",
    "        \n",
    "        ind_cnt += df[col].nunique()\n",
    "        ind_dict[col] = sub_dict\n",
    "    \n",
    "    if _model==\"ffm\":\n",
    "        add_field = 1\n",
    "    else:\n",
    "        add_field = 0\n",
    "    \n",
    "    nrow = df.shape[0]\n",
    "    \n",
    "    \n",
    "    #write into a text file : ffm/fm processed data\n",
    "    #val = f.split(\",\")\n",
    "    \n",
    "    text_file = open(filename,'w')\n",
    "       \n",
    "    for r in range(nrow):\n",
    "        datastring = \"\"\n",
    "        x = df.iloc[r].to_dict()\n",
    "        datastring += str(int(x['rating']))\n",
    "        x.pop('rating',None)\n",
    "        \n",
    "        for c in x.keys():\n",
    "            datastring += \",\" + (c + \":\") * add_field + str(int(ind_dict[c][x[c]])) + \":\" + \"1\"\n",
    "          \n",
    "        datastring += \"\\n\"\n",
    "        text_file.write(datastring)\n",
    "        \n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
